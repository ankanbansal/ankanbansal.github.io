<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Zero-Shot Object Detection</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Ankan Bansal</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="education.html">Education</a></div>
<div class="menu-item"><a href="courses.html">Courses</a></div>
<div class="menu-item"><a href="extracurrics.html">Extracurricular&nbsp;Activities</a></div>
<div class="menu-item"><a href="A.Bansal_Resume.pdf">Resume</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
<div class="menu-item"><a href="https://computervizion.blogspot.com/">Blog</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Zero-Shot Object Detection</h1>
<div id="subtitle">Ankan Bansal, <a href="https://ksikka.com/">Karan Sikka</a>*, <a href="http://www.grvsharma.com/research.html">Gaurav Sharma</a>^, Rama Chellappa, and Ajay Divakaran*<br />
* SRI International, Princeton, NJ<br />
^ NEC Labs America, Cupertino, CA</div>
</div>
<table class="imgtable"><tr><td>
<img src="projects/zsd/system_diagram.png" alt="System" width="900px" height="300px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p><font size=2><b>Fig. 1:</b> We highlight the task of zero-shot object detection where object classes “arm”, 
“hand”, and “shirt” are observed (seen) during training, while classes “skirt”, and
“shoulder” are not seen. These unseen classes are localized by our approach that leverages
semantic relationships, obtained via word embeddings, between seen and unseen classes
along with the proposed zero-shot detection framework. The example has been generated by
our model on images from VisualGenome dataset.</font></p>
<p><br />
<b>Abstract</b>: In this work, we introduce and tackle the problem of zero-shot object detection (ZSD), which
aims to detect object classes which are not observed during training. We work with a
challenging set of object classes, not restricting ourselves to similar and/or fine-grained
categories cf. prior works on zero-shot classification. We follow a principled approach by
first adapting visual-semantic embeddings for ZSD. We then discuss the problems associated
with selecting a background class and motivate two background-aware approaches for learning 
robust detectors. One of these models uses a fixed background class and the other is based 
on iterative latent assignments. We also outline the challenge associated with using a 
limited number of training classes and propose a solution based on dense sampling of the 
semantic label space using auxiliary data with a large number of categories. We propose 
novel splits of two standard detection datasets – MSCOCO and VisualGenome, and discuss 
extensive empirical results to highlight the benefits of the proposed methods. We provide 
useful insights into the algorithm and conclude by posing some open questions to encourage 
further research.</p>
<h2>Results</h2>
<p><b>We highlight the results obtained on unseen classes in the following figure.</b><br />








</p>
<table class="imgtable"><tr><td>
<img src="projects/zsd/results1.png" alt="results" width="1200px" height="320px" />&nbsp;</td>
<td align="left"></td></tr></table>
<table class="imgtable"><tr><td>
<img src="projects/zsd/results2.png" alt="results" width="1200px" height="320px" />&nbsp;</td>
<td align="left"></td></tr></table>
<table class="imgtable"><tr><td>
<img src="projects/zsd/results3.png" alt="results" width="1200px" height="320px" />&nbsp;</td>
<td align="left"></td></tr></table>
<table class="imgtable"><tr><td>
<img src="projects/zsd/results4.png" alt="results" width="1200px" height="320px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p><font size=2><b>Fig. 2:</b> This figure shows some detections made by our background-aware methods. We
have used Latent Assignment Based (LAB) model for VisualGenome (rows 1-2) and the Static
Background (SB) model (rows 3-4) for MSCOCO. Reasonable detections are shown in blue
and two failure cases in red. This figure highlights the effectiveness of our methods in
being able to detect unseen classes in a zero-shot setting.</font></p>
<h2>Downloads</h2>
<p>We are releasing our seen and unseen class names and train and test splits. This is an attempt to
standardize the work done in this area. </p>
<h3>VG</h3>
<p><b>Train and Test splits</b></p>
<ul>
<li><p><a href="https://obj.umiacs.umd.edu/zsd_files/vg_train_list.json.tar.gz">Train Bounding Boxes</a></p>
</li>
<li><p><a href="files/vg_test_list.txt">Test File List</a></p>
</li>
</ul>
<p><b>Seen and Unseen classes</b></p>
<ul>
<li><p><a href="files/vg_seen_classes.json">Seen Classes</a></p>
</li>
<li><p><a href="files/vg_unseen_classes.json">Unseen Classes</a></p>
</li>
</ul>
<p><b>Synset-Word Dictionary</b></p>
<ul>
<li><p><a href="files/vg_synset_word_dict.json">Synset-Word Dict</a></p>
</li>
</ul>
<h3>MSCOCO</h3>
<p><b>Train and Test splits</b></p>
<ul>
<li><p><a href="https://obj.umiacs.umd.edu/zsd_files/mscoco_train_list.json.tar.gz">Train Bounding Boxes</a> (Note that these bounding boxes are from about 
44,000 unique images. We started with about 73k images and after removing those with unseen classes, were left with 44k images.)</p>
</li>
<li><p><a href="files/mscoco_test_list.txt">Test File List</a></p>
</li>
</ul>
<p><b>Seen and Unseen classes</b></p>
<ul>
<li><p><a href="files/mscoco_seen_classes.json">Seen Classes</a></p>
</li>
<li><p><a href="files/mscoco_unseen_classes.json">Unseen Classes</a></p>
</li>
</ul>
<p><b>Synset-Word Dictionary</b></p>
<ul>
<li><p><a href="files/mscoco_synset_word_dict.json">Synset-Word Dict</a></p>
</li>
</ul>
<h2>Paper</h2>
<p>Our paper is available <a href="https://arxiv.org/abs/1804.04340">here</a>.</p>
<p>If you found the paper and data useful, please consider citing our paper using the bibtex:<br /></p>
<div class="codeblock">
<div class="blockcontent"><pre>
@misc{bansal2018zero,
    Author = {Bansal, Ankan and Sikka, Karan and Sharma, Gaurav and Chellappa, Rama and Divakaran, Ajay},
    Title = {Zero-Shot Object Detection},
    Year = {2018},
    Eprint = {arXiv:1804.04340},
}
</pre></div></div>
<p><b>Acknowledgments</b></p>
<p>This project is sponsored by the Air Force Research Laboratory (AFRL) and Defense Advanced
Research Projects Agency (DARPA) under the contract number USAF/AFMC AFRL FA8750-16-C-0158.<br />
<b>Disclaimer</b>: The views, opinions, and/or findings expressed are those of the author(s) and
should not be interpreted as representing the official views or policies of the Department of
Defense or the U.S. Government.</p>
<p>This work is also supported by the Intelligence Advanced Research Projects Activity (IARPA)
via Department of Interior/Interior Business Center (DOI/IBC) contract number D17PC00345. The
U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes not
withstanding any copyright annotation thereon.<br />
<b>Disclaimer</b>: The views and conclusions contained
herein are those of the authors and should not be interpreted as necessarily representing the
official policies or endorsements, either expressed or implied of IARPA, DOI/IBC or the U.S.
Government.</p>
<div id="footer">
<div id="footer-text">
Page generated 2019-04-17 01:51:55 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
